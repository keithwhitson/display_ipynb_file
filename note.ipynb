import pandas as pd

predict_sales = spark.read.csv("/home/kwhitson/travel_man_data/predict_sales.csv", inferSchema=True, header=True)

predict_sales.printSchema()

predict_sales_pandas_DF = predict_sales.toPandas()

predict_sales_pandas_DF.describe()

predict_sales_pandas_DF.corr()

predict_sales.describe()

predict_sales = sqlContext.sql("SELECT Store, Dept, Date, Weekly_Sales label, IsHoliday, Month(Date) Month,  Year(Date) Year, Day(Date) Day FROM predict_sales")

### Beneath that the schema of the data is included

from pyspark.sql.functions import col , column
predict_sales = predict_sales.withColumn("IsHoliday_String", col("IsHoliday").cast("string"))
predict_sales.printSchema()

### The Vector Assembler turns the non-label fields into a feature vector for applying the algorithm 
### The pipeline strings everything together so that you can apply the functions to the data in order

# Add the pipeline and tokenizer 
from pyspark.ml.feature import VectorAssembler, StringIndexer
from pyspark.ml import Pipeline

IsHoliday_stringIdx = StringIndexer(inputCol="IsHoliday_String", outputCol="IsHoliday_Stringh_indexed").setHandleInvalid("skip")

vector_assembler = VectorAssembler(inputCols=["IsHoliday_Stringh_indexed","Store","Dept","Month","Year","Day"], outputCol="features").setHandleInvalid("skip")

predict_sales_pandas_DF = predict_sales.toPandas()
predict_sales_corr = predict_sales_pandas_DF.corr()
predict_sales_corr_DF = spark.createDataFrame(predict_sales_corr)
predict_sales_corr_DF.createOrReplaceTempView("predict_sales_corr")
print(predict_sales_corr)

# The exact pipeline
pipeline = Pipeline(stages=[IsHoliday_stringIdx, vector_assembler])
pipelineFit = pipeline.fit(predict_sales)

dataset = pipelineFit.transform(predict_sales)

dataset.take(5)

dataset.createOrReplaceTempView("dataset")

train, test = dataset.randomSplit([0.7, 0.3], seed = 1)
train.createOrReplaceTempView("train")

from pyspark.ml.regression import LinearRegression
lr = LinearRegression(featuresCol = "features", labelCol="label", maxIter=10, regParam=0.3, elasticNetParam=0.8)
lr_model = lr.fit(train)
print("Coefficients: " + str(lr_model.coefficients))
print("Intercept: " + str(lr_model.intercept))

trainingSummary = lr_model.summary
print("RMSE: %f" % trainingSummary.rootMeanSquaredError)
print("r2: %f" % trainingSummary.r2)

from pyspark.ml.regression import RandomForestRegressor
from pyspark.ml.evaluation import RegressionEvaluator

## The Random Forest model is trained

rfr = RandomForestRegressor(featuresCol="features",labelCol="label")
rfrModel = rfr.fit(train)
predictions = rfrModel.transform(test)

## A field is renamed because the Evaluator looks for that name

predictions = predictions.withColumnRenamed("prediction","rawPrediction")

## A peak at the data with the predictions

predictions.show()

### Analyze the results of the predictions

from pyspark.ml.evaluation import BinaryClassificationEvaluator
evaluator = BinaryClassificationEvaluator()
print("Test Area Under ROC: " + str(evaluator.evaluate(predictions, {evaluator.metricName: "areaUnderROC"})))

### In this case, this model performs much better than the linear regression model.  

from pyspark.ml.regression import GBTRegressor
gbt = GBTRegressor(featuresCol="features", maxIter=10)
gbtModel = gbt.fit(train)
predictions = gbtModel.transform(test)

predictions = predictions.withColumnRenamed("prediction","rawPrediction")

from pyspark.ml.evaluation import BinaryClassificationEvaluator
evaluator = BinaryClassificationEvaluator()
print("Test Area Under ROC: " + str(evaluator.evaluate(predictions, {evaluator.metricName: "areaUnderROC"})))

from pyspark.ml.regression import DecisionTreeRegressor
dt = DecisionTreeRegressor(featuresCol="features")
model = dt.fit(train)
predictions = model.transform(test)

predictions = predictions.withColumnRenamed("prediction","rawPrediction")

from pyspark.ml.evaluation import BinaryClassificationEvaluator
evaluator = BinaryClassificationEvaluator()
print("Test Area Under ROC: " + str(evaluator.evaluate(predictions, {evaluator.metricName: "areaUnderROC"})))